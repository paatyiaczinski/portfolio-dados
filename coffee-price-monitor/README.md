# â˜• Coffee Pricing: Web Scraping and Analysis

This project collects daily prices of coffee-related products (ground coffee, beans, cappuccinos, and accessories) from major Brazilian online retailers such as Mercado Livre, Americanas, and Magazine Luiza.

It uses Python-based web scraping techniques to extract, clean, and store data in a cloud PostgreSQL database (Supabase), enabling automated updates and potential integration with dashboards.

---

## ğŸ“Œ Technologies Used

- Python 3.11+
- BeautifulSoup & Requests (for static scraping)
- Selenium (for dynamic pages)
- Pandas
- SQLAlchemy
- Supabase (PostgreSQL cloud database)
- GitHub Actions (future automation)

---

## ğŸ§± Project Structure

```bash
coffee-price-monitor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/                 # Scrapers for each store (ML, Magalu, Americanas)
â”‚   â”œâ”€â”€ processors/               # Data cleaning and transformation
â”‚   â”œâ”€â”€ upload/                   # Data upload to Supabase
â”‚   â”œâ”€â”€ main.py                   # Main execution file
â”‚   â””â”€â”€ mercado_livre_selenium.py # Alternative version using Selenium
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run

```bash
# Install dependencies
pip install -r requirements.txt

# Copy environment config
cp .env.example .env

# Edit the .env with your Supabase credentials
# Then run:
python src/main.py
```

---

## ğŸ” Security

- Secrets are managed via `python-dotenv` and are not committed to the repository.
- `.env.example` contains all required variables for setup.

---

## ğŸ“ˆ Next Steps

- Automate daily scraping with GitHub Actions
- Connect to Power BI or Metabase for analysis
- Expand to more categories or regions